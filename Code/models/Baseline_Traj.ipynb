{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline_Traj.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NVsPhIdQW8-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d30bb71c-f0f3-48bc-89c2-93c2ad74e3fc"
      },
      "source": [
        "# needed libraries\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Conv2DTranspose\n",
        "from tensorflow.keras.layers import Flatten, Reshape, Dropout, BatchNormalization, Activation, LeakyReLU\n",
        "\n",
        "# utilities\n",
        "import os\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "gpu_available = tf.config.list_physical_devices('GPU')\n",
        "print(gpu_available)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pickle5\n",
        "import pickle5 as pickle\n",
        "\n",
        "# store processed data in pkl files\n",
        "def save_pkl_data(data, filename):\n",
        "    with open(filename, 'wb') as file:\n",
        "        pickle.dump(data, file, pickle.HIGHEST_PROTOCOL)\n",
        "        print(\"data stored succesfully to: \", filename)\n",
        "\n",
        "\n",
        "# read processed data in pkl files\n",
        "def load_pkl_data(filename):\n",
        "    with open(filename, 'rb') as file:\n",
        "        data = pickle.load(file)\n",
        "    return data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trLxIedJysba",
        "outputId": "97b3ef73-942c-49fc-ac0a-bdbae29066a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pickle5\n",
            "  Downloading pickle5-0.0.12-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (256 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▎                              | 10 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 20 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 30 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 40 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 51 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 81 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 256 kB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: pickle5\n",
            "Successfully installed pickle5-0.0.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cubes = load_pkl_data('nusc_inps.pkl') "
      ],
      "metadata": {
        "id": "x7yfHGkBzd3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Masking"
      ],
      "metadata": {
        "id": "Nux0ZPWEkULg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_look_ahead_mask(input):\n",
        "  input_shape = list(input.shape)[:-1]\n",
        "  input_shape.insert(-1, input_shape[-1])\n",
        "  input_shape.insert(1, 1)\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones(input_shape), -1, 0)\n",
        "  return mask"
      ],
      "metadata": {
        "id": "aP3nXwLZkSuk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adapt_spatial_mask(mask):\n",
        "  return mask[np.newaxis, : , np.newaxis, : ]         #(1, seq, 1, neighbors)"
      ],
      "metadata": {
        "id": "XiTKrQl_TImn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Positional Encoding"
      ],
      "metadata": {
        "id": "u7MKnzFQkVv5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IKXnqHHQsL3"
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oItHcbouQaKR"
      },
      "source": [
        "def positional_encoding(max_position, d_model):\n",
        "  angle_rads = get_angles(np.arange(max_position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "\n",
        "  # apply sin to even indices in the array; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "  # apply cos to odd indices in the array; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention"
      ],
      "metadata": {
        "id": "p-EO4nKanJbP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmod-0KwX4Yj"
      },
      "source": [
        "def ScaledDotProduct(Q, K, V, mask=None):\n",
        "    dk = tf.cast(tf.shape(K)[-1], tf.float32)\n",
        "\n",
        "    # compute attention \n",
        "    KT = tf.transpose(K, [0, 1, 2, 4, 3])                 \n",
        "    attention = tf.matmul(Q, KT)/tf.sqrt(dk)\n",
        "\n",
        "    # mask if necessary\n",
        "    if mask is not None:\n",
        "      #print(attention.shape)\n",
        "      attention += (mask * -1e9)\n",
        "\n",
        "    # compute values and weighted sum of their attention\n",
        "    weights = tf.nn.softmax(attention, axis=-1)\n",
        "    output = tf.matmul(weights, V)\n",
        "\n",
        "    return output, weights "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEUnKAzX7b4I"
      },
      "source": [
        "class MultiHeadAttention(keras.layers.Layer):\n",
        "  def __init__(self, dk=256, num_heads=8):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    \n",
        "    # params\n",
        "    self.num_heads = num_heads\n",
        "    self.dk = dk\n",
        "    self.dk_by_head = dk//num_heads\n",
        "\n",
        "    # layers\n",
        "    self.WQ = keras.layers.Dense(dk)\n",
        "    self.WK = keras.layers.Dense(dk)\n",
        "    self.WV = keras.layers.Dense(dk)\n",
        "    self.dense = keras.layers.Dense(dk)\n",
        "    \n",
        "  def splitheads(self, x):\n",
        "    batch_size, seq_length = x.shape[0:2]\n",
        "\n",
        "    # spliting the heads done by reshaping last dimension\n",
        "    x = tf.reshape(x, (batch_size, seq_length, -1, self.num_heads, self.dk_by_head))      #(batch, seq, neighbors, head, features_by_head)\n",
        "    return tf.transpose(x, (0, 3, 1, 2, 4))                                               #(batch, head, seq, neighbors, features_by_head)\n",
        "\n",
        "  def call(self, q, k, v, mask=None):\n",
        "    batch_size, seq_length = q.shape[0:2]\n",
        "\n",
        "    # projections\n",
        "    q = self.WQ(q)\n",
        "    k = self.WK(v)\n",
        "    v = self.WV(k)\n",
        "\n",
        "    # split heads\n",
        "    q = self.splitheads(q)\n",
        "    k = self.splitheads(k)\n",
        "    v = self.splitheads(v)\n",
        "\n",
        "    # compute attention and merge heads\n",
        "    attn_output, attention = ScaledDotProduct(q, k, v, mask)                              #(batch, head, seq, neighbors, features_by_head)\n",
        "    attn_output = tf.transpose(attn_output,  (0, 2, 3, 1, 4))                             #(batch, seq, neighbors, head, features_by_head)\n",
        "    concat_output = tf.reshape(attn_output, (batch_size, seq_length, -1, self.dk))        #(batch, seq, neighbors, features)\n",
        "    output = self.dense(concat_output)\n",
        "\n",
        "    return output, attention\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer Architecture"
      ],
      "metadata": {
        "id": "l7Ab42_LnOar"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_FFPE5rHQeI"
      },
      "source": [
        "def get_ffn(d_model, hidden_size, act_func='relu'):\n",
        "  return keras.models.Sequential([\n",
        "                                  keras.layers.Dense(hidden_size, activation=act_func),\n",
        "                                  keras.layers.Dense(d_model)\n",
        "  ], name='SEQ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwYCmqYIEs5K"
      },
      "source": [
        "class EncoderLayer(keras.layers.Layer):\n",
        "  def __init__(self, dk=256, num_heads=8, hidden_layer_size=256, use_dropout=True, drop_rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "    # params\n",
        "    self.use_dropout = use_dropout\n",
        "\n",
        "    # layers\n",
        "    self.MH = MultiHeadAttention(dk, num_heads)\n",
        "    self.ffn = get_ffn(dk, dk, 'relu')\n",
        "    self.normLayer1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.normLayer2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.dropout1 = keras.layers.Dropout(drop_rate)\n",
        "    self.dropout2 = keras.layers.Dropout(drop_rate)\n",
        "\n",
        "  def call(self, x, training, mask):\n",
        "    # multihead attention\n",
        "    attn_output, _ = self.MH(x, x, x, mask)\n",
        "\n",
        "    # dropout layer\n",
        "    if self.use_dropout and training:\n",
        "      attn_output = self.dropout1(attn_output)\n",
        "    \n",
        "    # normalization and feed forward layers\n",
        "    z = self.normLayer1(x + attn_output)\n",
        "    output = self.ffn(z)\n",
        "\n",
        "    # dropout layer\n",
        "    if self.use_dropout and training:\n",
        "      output = self.dropout2(output)\n",
        "    \n",
        "    # normalization layer\n",
        "    output = self.normLayer2(z + output)\n",
        "\n",
        "    return output "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98ekRaNEvMjo"
      },
      "source": [
        "sample_encoder_layer = EncoderLayer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJHE0M97vihK",
        "outputId": "56b71cef-e5ac-401c-f2e4-4bc81fb03ef9"
      },
      "source": [
        "samp_inp = tf.random.uniform((3, 20, 6, 256))\n",
        "out = sample_encoder_layer(samp_inp, True, None)\n",
        "out.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([3, 20, 6, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJhiiUwqAmvJ"
      },
      "source": [
        "class DecoderLayer(keras.layers.Layer):\n",
        "  def __init__(self, dk=256, num_heads=8, hidden_layer=256, use_dropout=True, drop_rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    #params\n",
        "    self.use_dropout = use_dropout\n",
        "\n",
        "    # layers\n",
        "    self.SAMH = MultiHeadAttention(dk, num_heads)\n",
        "    self.EDMH = MultiHeadAttention(dk, num_heads)\n",
        "    self.ffn = get_ffn(dk, hidden_layer)\n",
        "\n",
        "    self.normLayer1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.normLayer2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.normLayer3 = keras.layers.LayerNormalization(epsilon=1e-6)\\\n",
        "\n",
        "    self.dropout1 = keras.layers.Dropout(drop_rate)\n",
        "    self.dropout2 = keras.layers.Dropout(drop_rate)\n",
        "    self.dropout3 = keras.layers.Dropout(drop_rate)\n",
        "  \n",
        "  def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "\n",
        "    # self attention computation\n",
        "    self_attn_out, self_attn = self.SAMH(x, x, x, look_ahead_mask)\n",
        "\n",
        "    if self.use_dropout and training:\n",
        "      self_attn_out = self.dropout1(self_attn_out)\n",
        "    \n",
        "    z = self.normLayer1(x + self_attn_out) \n",
        "\n",
        "    # encoder decoder computation\n",
        "    enc_dec_out, enc_dec_attn = self.EDMH(z, enc_output, enc_output, padding_mask)\n",
        "\n",
        "    if self.use_dropout and training:\n",
        "      enc_dec_out = self.dropout2(enc_dec_out)\n",
        "    \n",
        "    z = self.normLayer2(z + enc_dec_out)\n",
        "\n",
        "    # feed forward computation\n",
        "    output = self.ffn(z)\n",
        "\n",
        "    if self.use_dropout and training:\n",
        "      output = self.dropout3(output)\n",
        "    \n",
        "    output = self.normLayer3(z + output)\n",
        "\n",
        "    return output, self_attn, enc_dec_attn\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXerYKS7vJBC"
      },
      "source": [
        "sample_decoder_layer = DecoderLayer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y19KWa5EzF1u",
        "outputId": "8127c674-ea51-4f4c-952a-34a547d18228"
      },
      "source": [
        "dec_inp = tf.random.uniform((3, 20, 6, 256))\n",
        "out2 = sample_decoder_layer(dec_inp, out, True, None, None)\n",
        "out2[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([3, 20, 6, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jBOAtR05aGn"
      },
      "source": [
        "class Encoder(keras.layers.Layer):\n",
        "  def __init__(self, features_size, max_size, dk_model=256, num_heads=8, num_encoders=6, \n",
        "               enc_hidden_size=256, use_pos_emb=True, use_dropout=True, drop_rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    # params\n",
        "    self.dk_model = dk_model\n",
        "    self.max_size = max_size\n",
        "    self.use_dropout = use_dropout\n",
        "    self.use_pos_emb = use_pos_emb\n",
        "    self.enc_hidden_size = enc_hidden_size\n",
        "    self.num_encoders = num_encoders\n",
        "\n",
        "    # layers\n",
        "    #self.embedding = keras.layers.Embedding(features_size, dk_model)\n",
        "    self.embedding = keras.layers.Dense(dk_model)\n",
        "    self.encoders_stack = [EncoderLayer(dk_model, num_heads, enc_hidden_size, use_dropout, drop_rate) for _ in range(num_encoders)]\n",
        "    self.dropout = tf.keras.layers.Dropout(drop_rate)\n",
        "  \n",
        "  def call(self, x, padding_mask, training):\n",
        "    x = self.embedding(x)\n",
        "    x *= tf.math.sqrt(tf.cast(self.dk_model, tf.float32))\n",
        "\n",
        "    if self.use_pos_emb:\n",
        "      x += positional_encoding(self.max_size, self.dk_model)\n",
        "    \n",
        "    if self.use_dropout and training:\n",
        "      x = self.dropout(x)\n",
        "    \n",
        "    for encoder_layer in self.encoders_stack:\n",
        "      x = encoder_layer(x, training, padding_mask)\n",
        "    \n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mPf0yfTBQmf",
        "outputId": "2b03d983-b381-47f3-fa44-6bec338c9dbc"
      },
      "source": [
        "samp_inp = tf.random.uniform((3, 6, 20, 256))\n",
        "encoder = Encoder(256, 20, 256)\n",
        "out = encoder(samp_inp, None, True)\n",
        "out.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HI\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([3, 6, 20, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxqvjK00I7q_"
      },
      "source": [
        "class Decoder(keras.layers.Layer):\n",
        "  def __init__(self, features_size, max_size, dk_model=256, num_heads=8, num_decoders=6, \n",
        "               dec_hidden_size=256, use_pos_emb=True, use_dropout=True, drop_rate=0.1):\n",
        "    \n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    # params\n",
        "    self.dk_model = dk_model\n",
        "    self.max_size = max_size\n",
        "    self.use_dropout = use_dropout\n",
        "    self.use_pos_emb = use_pos_emb\n",
        "    self.dec_hidden_size = dec_hidden_size\n",
        "    self.num_decoders = num_decoders\n",
        "\n",
        "    # layers\n",
        "    self.embedding = keras.layers.Dense(dk_model)\n",
        "    self.decoders_stack = [DecoderLayer(dk_model, num_heads, dec_hidden_size, use_dropout, drop_rate) for _ in range(num_decoders)]\n",
        "    self.dropout = tf.keras.layers.Dropout(drop_rate)\n",
        "\n",
        "  def call(self, x, enc_output, look_ahead_mask, padding_mask, training):\n",
        "    #print(x)\n",
        "    x = self.embedding(x)\n",
        "    #print(x)\n",
        "    x *= tf.math.sqrt(tf.cast(self.dk_model, tf.float32))\n",
        "    if self.use_pos_emb:\n",
        "      x += positional_encoding(self.max_size, self.dk_model)\n",
        "    \n",
        "    #print(x)\n",
        "    if self.use_dropout and training:\n",
        "      x = self.dropout(x)\n",
        "    \n",
        "    for decoder_layer in self.decoders_stack:\n",
        "      x, attn1, attn2, = decoder_layer(x, enc_output, training, look_ahead_mask, padding_mask)\n",
        "    \n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TJsP0rtQf83",
        "outputId": "5eabc61f-5230-4180-cfb5-5fe5c004c98b"
      },
      "source": [
        "samp_inp = tf.random.uniform((3, 6, 20, 256))\n",
        "decoder = Decoder(256, 20, 256)\n",
        "out2 = decoder(samp_inp, out, None, None, True)\n",
        "out2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HI\n",
            "xs:  (3, 6, 20, 256)\n",
            "pe:  (1, 20, 256)\n",
            "xs:  (3, 6, 20, 256)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([3, 6, 20, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9gQwvAEa6JJ"
      },
      "source": [
        "class STTransformer(keras.Model):\n",
        "  def __init__(self, features_size, max_seq_size, max_neighbors_size, \n",
        "               sp_dk=256, sp_enc_heads=8, sp_dec_heads=8, sp_num_encoders=6, sp_num_decoders=6, \n",
        "               tm_dk=256, tm_enc_heads=8, tm_dec_heads=8, tm_num_encoders=6, tm_num_decoders=6, \n",
        "               dec_hidden_size=256, use_dropout=True, drop_rate=0.1):\n",
        "    \n",
        "    super(STTransformer, self).__init__()\n",
        "\n",
        "    # layers\n",
        "    self.sp_encoder = Encoder(features_size, max_neighbors_size, sp_dk, use_pos_emb=False)\n",
        "    self.sp_decoder = Decoder(features_size, max_neighbors_size, sp_dk, use_pos_emb=False)\n",
        "    self.tm_encoder = Encoder(features_size, max_seq_size, tm_dk)\n",
        "    self.tm_decoder = Decoder(features_size, max_seq_size, tm_dk)\n",
        "    self.linear = tf.keras.layers.Dense(3, name='Linear_Trans')\n",
        "\n",
        "    \n",
        "  def call(self, inputs, masks, training):\n",
        "    inp, targets = inputs\n",
        "    inp_mask, tar_mask = masks\n",
        "    \n",
        "\n",
        "    sp_enc_out = self.sp_encoder(inp,  inp_mask, training)                             #(batch, seq, neighbors, <spatial attn features>)\n",
        "    out = tf.transpose(sp_enc_out, [0, 2, 1, 3])                                       #(batch, neighbors, seq, <spatial attn features>)\n",
        "    tm_enc_out = self.tm_encoder(out, None, training)                                  #(batch, neighbots, seq, <time attn features>)\n",
        "    \n",
        "    # decode time\n",
        "    targets = tf.transpose(targets, [0, 2, 1, 3])                                      #(batch, neighbors, seq, features)\n",
        "    look_mask = get_look_ahead_mask(targets)\n",
        "    tm_dec_out = self.tm_decoder(targets, tm_enc_out, look_mask, None, training)\n",
        "    out2 = tf.transpose(tm_dec_out, [0, 2, 1, 3])                                      #(batch, seq, neighbors, features)\n",
        "    sp_dec_out = self.sp_decoder(out2, sp_enc_out, None, tar_mask, training)\n",
        "    \n",
        "    # linear projection\n",
        "    output = self.linear(sp_dec_out)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "capRr2Fl_XNw"
      },
      "source": [
        "model = STTransformer(100, 20, 6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMcNVIeu_3cq"
      },
      "source": [
        "input = tf.random.uniform((8, 8, 10, 5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = tf.random.uniform((8, 8, 10, 5))"
      ],
      "metadata": {
        "id": "-nDYPgSUvKMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = (input, target)"
      ],
      "metadata": {
        "id": "sv8ZSnsovTk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CmOgF0uAYta"
      },
      "source": [
        "o = model(inputs, (None, None))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_cqvWb9jFpN",
        "outputId": "42bf9aaf-c8a0-4220-b2a7-587f166322d7"
      },
      "source": [
        "o.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([8, 10, 6, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(o)"
      ],
      "metadata": {
        "id": "8TlwfNQS6pxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def buildDataSet(input, batch_size):\n",
        "  input_dataset = tf.data.Dataset.from_tensor_slices([x[0].astype(np.float32) for x in input])\n",
        "  mask_dataset = tf.data.Dataset.from_tensor_slices([ adapt_spatial_mask(x[1].astype(np.float32)) for x in input])\n",
        "  #mask_dataset = adapt_spatial_mask(mask_dataset)\n",
        "  dataset = tf.data.Dataset.zip((input_dataset, mask_dataset))\n",
        "  dataset = dataset.shuffle(40)\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "N9OyGWldeJ9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = buildDataSet(cubes, 16)"
      ],
      "metadata": {
        "id": "N0fnkEQk0h3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = tf.keras.losses.MeanSquaredError()"
      ],
      "metadata": {
        "id": "-KumylNDtudp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optimizer = tf.keras.optimizers.Adam(0.0001, beta_1=0.9, beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ],
      "metadata": {
        "id": "h2KxT0Zcy-hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = STTransformer(16, 8, 10)"
      ],
      "metadata": {
        "id": "BwHu9EMU1rDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@tf.function\n",
        "def train_step(zipped_input, l, losses):\n",
        "  inputs = zipped_input[0]\n",
        "  masks = zipped_input[1]\n",
        "\n",
        "  # divide input as the trajectory input, and target (basically past and future to predict) \n",
        "  inp, tar = inputs[:, :l, :, :], inputs[:, l-1:, :, :]                   \n",
        "  mask_inp, mask_tar = masks[:, :, :l, :, :], masks[:, :, l-1:, :, :]\n",
        "  \n",
        "  # get only x, y, and rotation\n",
        "  targets = tar[:, :, :, :3]                                            \n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model((inp, tar), (mask_inp, mask_tar), training=True)\n",
        "    loss = loss_function(targets, predictions)\n",
        "\n",
        "  #print('targets: ', targets.numpy())\n",
        "  #print(predictions)\n",
        "  print('loss: ', loss)\n",
        "  losses.append(loss)\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  return losses"
      ],
      "metadata": {
        "id": "UIDyvCrwiSpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "1OW2kykQ7iMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(20):\n",
        "  print('epoch: ', epoch)\n",
        "  losses = []\n",
        "  for batch in dataset:\n",
        "    losses = train_step(batch, 8, losses)\n",
        "\n",
        "  print(\"avg loss\", tf.reduce_mean(losses)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMQdHyG02AeR",
        "outputId": "e0e7ff7e-ee08-4c5c-f4e1-50978d197531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0\n",
            "loss:  tf.Tensor(987.5495, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1939.2532, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1026.8756, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(866.13904, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1261.075, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1148.3922, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1421.7554, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1280.4187, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(820.8073, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1481.7888, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1886.6484, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1946.199, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2714.373, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1900.1019, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2521.305, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2401.936, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2739.5632, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1523.3484, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1330.3943, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(3150.741, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1909.9363, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1271.668, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1216.4426, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2159.8223, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1655.7649, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2174.7117, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1776.883, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2337.4421, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1860.5862, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2063.4119, shape=(), dtype=float32)\n",
            "avg loss tf.Tensor(1759.1779, shape=(), dtype=float32)\n",
            "epoch:  1\n",
            "loss:  tf.Tensor(1470.392, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1594.1443, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(721.5909, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1233.6783, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1200.3859, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1201.373, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1107.4259, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(901.10236, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1767.1234, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1537.6599, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1219.3718, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(984.8529, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2114.9727, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2474.5715, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(3332.3125, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2108.4358, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2183.327, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1554.6082, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1733.3848, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1999.179, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2772.3813, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1582.3884, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1862.9391, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1022.0189, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1549.0382, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2186.6213, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2976.2236, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1603.524, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1835.7197, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2246.3723, shape=(), dtype=float32)\n",
            "avg loss tf.Tensor(1735.9039, shape=(), dtype=float32)\n",
            "epoch:  2\n",
            "loss:  tf.Tensor(1051.0701, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1641.4574, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(956.5099, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(857.2709, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1290.8446, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1505.0603, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1514.0815, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1119.3998, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1752.9043, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1010.084, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1089.2452, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1517.6384, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2337.669, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2458.651, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2503.151, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1607.4049, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2237.2737, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2518.1921, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2030.7877, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1878.6324, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1920.761, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1736.5807, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1675.7035, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1746.6342, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1509.5966, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2283.7407, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2173.3691, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1875.5973, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2097.205, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1833.995, shape=(), dtype=float32)\n",
            "avg loss tf.Tensor(1724.3503, shape=(), dtype=float32)\n",
            "epoch:  3\n",
            "loss:  tf.Tensor(909.07764, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1324.2937, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1259.116, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(849.8895, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1979.4076, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1028.9934, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(930.31134, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1508.4385, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1271.991, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2061.1382, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(966.7672, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1151.2712, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2686.4038, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1851.5769, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2726.869, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1941.9355, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2612.7214, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1780.0215, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1472.0599, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2865.6326, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2350.4116, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1887.7119, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1080.6453, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1491.4265, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1772.0045, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1737.0082, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2486.961, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2555.7336, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1279.1586, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1661.6307, shape=(), dtype=float32)\n",
            "avg loss tf.Tensor(1716.0203, shape=(), dtype=float32)\n",
            "epoch:  4\n",
            "loss:  tf.Tensor(1314.105, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1182.2009, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1103.9456, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1475.1149, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1191.4519, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1336.0437, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1154.4197, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1479.2823, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1429.2689, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1173.6409, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1643.9651, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1704.7273, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1950.7289, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2099.3394, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2568.1921, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1740.1986, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1944.641, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2143.1301, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1216.0897, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2492.1287, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2156.9783, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2256.6733, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(758.8165, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2179.0107, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1662.1637, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2530.6558, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1949.7672, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1653.7322, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2285.5635, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1827.4276, shape=(), dtype=float32)\n",
            "avg loss tf.Tensor(1720.1134, shape=(), dtype=float32)\n",
            "epoch:  5\n",
            "loss:  tf.Tensor(1229.0219, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1262.3502, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1333.693, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1092.9402, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(924.6886, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1259.2441, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1278.2229, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1033.3152, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1602.0087, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1478.5544, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1752.2266, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1848.3838, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2089.4734, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2818.191, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2483.15, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1750.1982, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1763.7998, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2212.981, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1277.6411, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2400.6724, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2081.1309, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2074.01, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1308.8164, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1524.49, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1725.7035, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1511.2473, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1763.183, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2004.3806, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2548.7065, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2205.488, shape=(), dtype=float32)\n",
            "avg loss tf.Tensor(1721.2638, shape=(), dtype=float32)\n",
            "epoch:  6\n",
            "loss:  tf.Tensor(910.8589, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1491.0486, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(828.92285, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1545.446, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1090.301, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1544.0258, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(969.0419, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1289.7839, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1624.5048, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1527.5658, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1430.0386, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1397.5691, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1419.9602, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(3520.7852, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2051.8547, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1804.1364, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2325.5415, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1991.9573, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2173.6694, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1823.1771, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1003.258, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2039.5035, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1574.5916, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1545.7942, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2394.318, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1945.2383, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1884.406, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1872.3281, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2424.1882, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2090.9412, shape=(), dtype=float32)\n",
            "avg loss tf.Tensor(1717.8253, shape=(), dtype=float32)\n",
            "epoch:  7\n",
            "loss:  tf.Tensor(1447.9176, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1191.0627, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1540.3341, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1227.4407, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(866.3913, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(736.72107, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1462.4808, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1173.7971, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(792.6505, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1146.7654, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1732.1273, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1664.2281, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2149.1736, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2790.5376, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2215.2068, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2298.0234, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2167.402, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2592.9216, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2746.9133, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1543.4359, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1595.2418, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1822.8619, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1593.8599, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1084.771, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1766.0242, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2389.9124, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2205.7817, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1689.2354, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1695.8635, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2169.2673, shape=(), dtype=float32)\n",
            "avg loss tf.Tensor(1716.6117, shape=(), dtype=float32)\n",
            "epoch:  8\n",
            "loss:  tf.Tensor(1146.7145, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1512.5361, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1140.2367, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(698.77435, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1143.0015, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1703.4978, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1549.1847, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1244.0665, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(717.4785, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2059.489, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1734.2432, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1652.0852, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1598.5477, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2516.6548, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(3190.0623, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1588.6102, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2253.4438, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1548.1779, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1639.7351, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2559.8042, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1651.8757, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1277.5742, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1655.2386, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1696.8694, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2199.2532, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1365.1171, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1836.6584, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2299.397, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2482.5852, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1606.257, shape=(), dtype=float32)\n",
            "avg loss tf.Tensor(1708.9058, shape=(), dtype=float32)\n",
            "epoch:  9\n",
            "loss:  tf.Tensor(1639.5703, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1266.5635, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1350.8121, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(678.6508, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(982.20215, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1774.5974, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(851.6372, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1338.0564, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1419.3617, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(959.3763, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(948.5143, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1505.1201, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2210.8376, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2758.834, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2127.2993, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2618.1042, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2623.9473, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1942.4801, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1867.5186, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1819.9766, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1873.4961, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1603.6562, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1920.9086, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1858.9558, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1333.1198, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1499.9094, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2885.3228, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1694.2795, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2244.033, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1420.052, shape=(), dtype=float32)\n",
            "avg loss tf.Tensor(1700.5731, shape=(), dtype=float32)\n",
            "epoch:  10\n",
            "loss:  tf.Tensor(1598.155, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1273.2642, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1219.7, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(897.82587, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1075.9845, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(938.1131, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1047.315, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(882.73926, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1419.7766, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1545.8871, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2014.1951, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1602.3007, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1989.7819, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2858.1104, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2666.0784, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1512.675, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2623.0205, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2235.0842, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1866.2025, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1851.1094, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1727.1982, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1546.721, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1413.1322, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1665.594, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1446.4613, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1275.6155, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1204.9808, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2165.5535, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(3556.942, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2119.8103, shape=(), dtype=float32)\n",
            "avg loss tf.Tensor(1707.9777, shape=(), dtype=float32)\n",
            "epoch:  11\n",
            "loss:  tf.Tensor(1845.446, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1275.4314, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1801.51, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1202.974, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(722.6501, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(999.73987, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1004.5791, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1334.8936, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(865.6543, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(699.47345, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1510.6921, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1119.6189, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2228.1108, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2364.8325, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(3605.8958, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1916.5209, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2556.7822, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1954.2781, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1173.6494, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2172.758, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(3091.5444, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1471.8873, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1089.4592, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1388.945, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2594.3508, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1672.2107, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2533.5884, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1815.0164, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1535.9899, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1271.5667, shape=(), dtype=float32)\n",
            "avg loss tf.Tensor(1694.0016, shape=(), dtype=float32)\n",
            "epoch:  12\n",
            "loss:  tf.Tensor(1768.2015, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1026.4385, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1009.1865, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(976.3664, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(943.86066, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1203.5432, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1574.8431, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1162.1555, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(982.36426, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1312.0398, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1481.4146, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1334.4514, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2222.4775, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1876.3313, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(3329.2466, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2240.9514, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2102.5054, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2206.0483, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1692.155, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1833.4215, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2023.9973, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1770.7766, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1630.1536, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1775.3469, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1796.0303, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1388.7821, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1865.3317, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(3167.2847, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1231.5077, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2475.6636, shape=(), dtype=float32)\n",
            "avg loss tf.Tensor(1713.4292, shape=(), dtype=float32)\n",
            "epoch:  13\n",
            "loss:  tf.Tensor(1273.0939, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1893.9648, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(927.3304, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(887.7152, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(803.0597, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1608.8601, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1228.1047, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1083.8174, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1138.5779, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2108.8594, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(958.85706, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1276.6897, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2582.8252, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2667.3882, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2122.1123, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1864.8004, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1763.4785, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2449.043, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1661.0703, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2169.352, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2123.1558, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1547.8949, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1895.6914, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1319.885, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2393.8872, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1926.8444, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1788.2393, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1374.9403, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1993.2523, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2391.3452, shape=(), dtype=float32)\n",
            "avg loss tf.Tensor(1707.4711, shape=(), dtype=float32)\n",
            "epoch:  14\n",
            "loss:  tf.Tensor(1514.3728, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(830.9702, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(798.31067, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1102.8693, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(942.109, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1724.6609, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1145.2065, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1195.9863, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1455.0314, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1766.6381, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1188.7936, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1891.7125, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2303.741, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2386.6987, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2894.4863, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1805.0758, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1814.0543, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1622.4187, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1914.8918, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1728.5984, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2449.707, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2108.916, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1774.0715, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1622.6511, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1920.749, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1675.3899, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1308.2413, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1833.0388, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2041.9965, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2546.6, shape=(), dtype=float32)\n",
            "avg loss tf.Tensor(1710.2662, shape=(), dtype=float32)\n",
            "epoch:  15\n",
            "loss:  tf.Tensor(1414.2625, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1506.2576, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1172.2166, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(781.8433, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1124.0947, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1449.885, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1845.5336, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(628.559, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1451.656, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1330.8029, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1252.5984, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1151.6982, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1352.0803, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2508.4165, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(3064.8223, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2450.1282, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2000.0388, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1529.4674, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2852.2769, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1890.4988, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1687.5867, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1523.0637, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1824.03, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2033.9076, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1882.1234, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1319.8713, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2263.495, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1856.1914, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1988.266, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1494.8643, shape=(), dtype=float32)\n",
            "avg loss tf.Tensor(1687.6844, shape=(), dtype=float32)\n",
            "epoch:  16\n",
            "loss:  tf.Tensor(852.7733, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1623.1212, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1802.4105, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(950.1034, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(812.2036, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1357.4606, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(709.0261, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1474.4414, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1130.5007, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1425.1774, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1124.8762, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2001.3494, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2458.4773, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2639.8806, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2764.9272, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1412.9656, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2907.1367, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1565.5142, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2217.2544, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1818.9043, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1630.3466, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1159.276, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1415.1265, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1792.7015, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1473.5131, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1997.018, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2119.1125, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2289.8052, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2534.0254, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1089.4686, shape=(), dtype=float32)\n",
            "avg loss tf.Tensor(1684.9633, shape=(), dtype=float32)\n",
            "epoch:  17\n",
            "loss:  tf.Tensor(1294.7415, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1076.4784, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1773.5192, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(441.3623, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1445.6838, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1008.1968, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1351.158, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1360.2002, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1054.5103, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(948.0114, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1788.3922, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1406.0969, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1940.1498, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2565.9114, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2631.2485, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2024.6023, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2513.5322, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2096.474, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1657.3324, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2063.3066, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1615.3718, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1200.5466, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2147.5972, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1719.6666, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1403.6876, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(3186.4885, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1987.2731, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1590.6316, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1235.0984, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2527.6218, shape=(), dtype=float32)\n",
            "avg loss tf.Tensor(1701.8297, shape=(), dtype=float32)\n",
            "epoch:  18\n",
            "loss:  tf.Tensor(752.3377, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1542.3708, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1829.5979, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(683.6322, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(788.2659, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1242.9392, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1457.0095, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(939.3392, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(783.74475, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1933.684, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1473.3865, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1538.9922, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1870.9153, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2692.8909, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2432.0107, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2477.0352, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1899.1045, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1525.632, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2541.6758, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1432.7892, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2746.515, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1154.4141, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2170.1802, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1535.9427, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1900.0336, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1755.4207, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1320.6444, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1747.3015, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2458.1519, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2876.8218, shape=(), dtype=float32)\n",
            "avg loss tf.Tensor(1716.7593, shape=(), dtype=float32)\n",
            "epoch:  19\n",
            "loss:  tf.Tensor(1204.5847, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(990.4302, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1282.6167, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1387.3456, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1421.8025, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1305.694, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1543.0188, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(829.7508, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1548.3909, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1025.5945, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1716.8787, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1392.8882, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1912.2289, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2634.0835, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2172.431, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1578.6198, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2159.9502, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2104.0015, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2046.5066, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1581.9666, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2819.0156, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1128.9873, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1392.031, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1550.4402, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2514.3555, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1666.3656, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2312.7603, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1898.3535, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(1597.9724, shape=(), dtype=float32)\n",
            "loss:  tf.Tensor(2238.5837, shape=(), dtype=float32)\n",
            "avg loss tf.Tensor(1698.5883, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ld = list(dataset)"
      ],
      "metadata": {
        "id": "a78xh9Ibyi_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = ld[0][0]\n",
        "masks = ld[0][1]\n",
        "\n",
        "# divide input as the trajectory input, and target (basically past and future to predict) \n",
        "inp, tar = inputs[:, :8, :, :], inputs[:, 8-2:, :, :]                   \n",
        "mask_inp, mask_tar = masks[:, :, :8, :, :], masks[:, :, 8-2:, :, :]\n",
        "out = model((inp, tar), (mask_inp, mask_tar))"
      ],
      "metadata": {
        "id": "7EfAfchgyq7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNUL8Ql7ztE2",
        "outputId": "6b0ade33-4227-4050-f9f1-adce8238b5a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(16, 8, 10, 5), dtype=float32, numpy=\n",
              "array([[[[-2.50668964e+01,  1.99907112e+01,  5.01123480e-02,\n",
              "           4.68301438e-02,  1.28885021e-03],\n",
              "         [ 1.52601032e+01, -1.27532883e+01,  2.04460174e-01,\n",
              "           7.03465509e+00, -1.41141748e+00],\n",
              "         [ 2.75801029e+01, -2.00642891e+01,  3.26544609e+01,\n",
              "           3.67394471e+00,  2.06004500e-01],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        [[-2.50738964e+01,  1.99687119e+01,  1.37068868e-01,\n",
              "           4.61850390e-02, -1.29053218e-03],\n",
              "         [ 1.27241030e+01, -1.06922884e+01,  2.04460174e-01,\n",
              "           6.53737402e+00, -9.94808674e-01],\n",
              "         [ 2.60571041e+01, -1.95842876e+01,  2.49544601e+01,\n",
              "           3.19449162e+00, -9.59144413e-01],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        [[-2.50818958e+01,  1.99467106e+01,  2.24025384e-01,\n",
              "           4.68309708e-02,  1.29220088e-03],\n",
              "         [ 1.03781033e+01, -8.79028893e+00,  2.04460174e-01,\n",
              "           6.04187489e+00, -9.91256118e-01],\n",
              "         [ 2.46041031e+01, -1.89242878e+01,  1.97544594e+01,\n",
              "           3.19257474e+00, -3.83472024e-03],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-2.51038971e+01,  1.98807106e+01,  4.84894961e-01,\n",
              "           4.67817485e-02,  1.19780167e-03],\n",
              "         [ 3.90310335e+00, -3.37928843e+00,  2.04460174e-01,\n",
              "           5.41748238e+00, -7.00838538e-03],\n",
              "         [ 1.71521034e+01, -1.54872885e+01,  5.75446033e+00,\n",
              "           4.99021387e+00, -5.15561104e-01],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        [[-2.51108971e+01,  1.98587112e+01,  5.71851492e-01,\n",
              "           4.61845733e-02, -1.19462924e-03],\n",
              "         [ 1.86810327e+00, -1.58828855e+00,  2.04460174e-01,\n",
              "           5.42306328e+00,  1.11649828e-02],\n",
              "         [ 1.50911036e+01, -1.40772886e+01,  2.75446010e+00,\n",
              "           4.99551392e+00,  1.06025347e-02],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        [[-2.51188965e+01,  1.98367119e+01,  6.58807993e-01,\n",
              "           4.67764214e-02,  1.18262030e-03],\n",
              "         [-2.98967287e-02,  8.97115096e-02, -1.29553986e+00,\n",
              "           5.06220293e+00, -7.21068144e-01],\n",
              "         [ 1.31071033e+01, -1.25612888e+01, -2.45539844e-01,\n",
              "           4.98928070e+00, -1.24549260e-02],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]]],\n",
              "\n",
              "\n",
              "       [[[-2.73887177e+01,  1.95812531e+01,  1.78551819e+02,\n",
              "           6.18284845e+00,  4.38569397e-01],\n",
              "         [-3.87837181e+01,  3.47942543e+01,  1.05992393e+02,\n",
              "           4.65655470e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        [[-2.37077179e+01,  1.78052540e+01,  1.76911316e+02,\n",
              "           7.44348192e+00,  2.29591417e+00],\n",
              "         [-3.86667175e+01,  3.22432518e+01,  1.15563293e+02,\n",
              "           4.65086222e+00, -1.03670573e-02],\n",
              "         [-3.66957169e+01,  4.13102531e+01,  9.03909378e+01,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        [[-2.02017174e+01,  1.61902523e+01,  1.76911316e+02,\n",
              "           7.72188711e+00,  5.56933939e-01],\n",
              "         [-3.80147171e+01,  2.94102535e+01,  1.27326317e+02,\n",
              "           5.81541061e+00,  2.32961416e+00],\n",
              "         [-3.75437164e+01,  3.87832527e+01,  9.92095337e+01,\n",
              "           5.33216333e+00,  0.00000000e+00],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-8.66171741e+00,  1.03282528e+01,  1.76627335e+02,\n",
              "           8.86146164e+00,  6.97304428e-01],\n",
              "         [-3.30857162e+01,  2.33482533e+01,  1.57279526e+02,\n",
              "           5.50222206e+00, -2.52474397e-01],\n",
              "         [-3.76707191e+01,  3.08482533e+01,  1.25665314e+02,\n",
              "           5.32790756e+00, -1.27632758e-02],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        [[-4.66971731e+00,  8.39925289e+00,  1.77343353e+02,\n",
              "           8.86916542e+00,  1.54111357e-02],\n",
              "         [-3.08087177e+01,  2.16562538e+01,  1.70035568e+02,\n",
              "           5.67487097e+00,  3.45371634e-01],\n",
              "         [-3.65947189e+01,  2.82062531e+01,  1.35402359e+02,\n",
              "           5.70663691e+00,  7.57620752e-01],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        [[-6.77717268e-01,  6.46925306e+00,  1.78059387e+02,\n",
              "           8.87065792e+00,  2.98576523e-03],\n",
              "         [-2.80617180e+01,  2.02062531e+01,  1.76108032e+02,\n",
              "           6.21417570e+00,  1.07891643e+00],\n",
              "         [-3.50867157e+01,  2.57842522e+01,  1.45139389e+02,\n",
              "           5.70781088e+00,  2.34924722e-03],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]]],\n",
              "\n",
              "\n",
              "       [[[ 7.67894602e+00,  6.80868864e+00, -1.77929718e+02,\n",
              "           5.92256904e-01, -5.18917805e-03],\n",
              "         [ 8.90294647e+00,  3.45776901e+01, -1.79691849e+02,\n",
              "           5.92771959e+00,  2.27907253e-03],\n",
              "         [ 1.77694607e+00,  1.88546886e+01,  1.77809158e+02,\n",
              "           6.51328611e+00,  8.18587601e-01],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        [[ 7.57194614e+00,  6.54868841e+00, -1.77904083e+02,\n",
              "           5.61436057e-01, -6.15455545e-02],\n",
              "         [ 1.01469460e+01,  3.70666885e+01, -1.79858521e+02,\n",
              "           5.55644608e+00, -7.41388142e-01],\n",
              "         [ 3.26294613e+00,  2.17576885e+01,  1.78809158e+02,\n",
              "           6.51228189e+00, -2.00477196e-03],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        [[ 7.46494627e+00,  6.28768826e+00, -1.77878433e+02,\n",
              "           5.65334380e-01,  7.81286508e-03],\n",
              "         [ 1.12659464e+01,  3.92876892e+01,  1.79974823e+02,\n",
              "           4.98425961e+00, -1.14674926e+00],\n",
              "         [ 4.65694618e+00,  2.47066879e+01,  1.78809158e+02,\n",
              "           6.53729677e+00,  5.01335599e-02],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 7.14994621e+00,  5.51968861e+00, -1.77801514e+02,\n",
              "           5.32978535e-01, -5.98996989e-02],\n",
              "         [ 1.45129461e+01,  4.57266884e+01,  1.79474823e+02,\n",
              "           4.78444386e+00, -5.71881980e-02],\n",
              "         [ 8.30194569e+00,  3.26016884e+01,  1.79809158e+02,\n",
              "           5.47627068e+00, -6.05902255e-01],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        [[ 7.04794598e+00,  5.27268839e+00, -1.77775879e+02,\n",
              "           5.36711752e-01,  7.49785965e-03],\n",
              "         [ 1.55949459e+01,  4.78726883e+01,  1.79308151e+02,\n",
              "           4.82689190e+00,  8.52529034e-02],\n",
              "         [ 9.47094631e+00,  3.50916901e+01,  1.79809158e+02,\n",
              "           5.52464771e+00,  9.71613079e-02],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        [[ 6.94694614e+00,  5.02468824e+00, -1.77750229e+02,\n",
              "           5.35681188e-01, -2.06156191e-03],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 1.06249456e+01,  3.75516891e+01,  1.79809158e+02,\n",
              "           5.43572426e+00, -1.77888796e-01],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[ 1.90291519e+01,  1.39791250e+01,  1.78382568e+02,\n",
              "           1.23583441e+01, -1.20526826e+00],\n",
              "         [-4.11118507e+01, -4.87978745e+01, -2.11543083e+00,\n",
              "           1.47413759e+01, -3.34716058e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        [[ 2.31381512e+01,  1.85611248e+01,  1.78382568e+02,\n",
              "           1.23120728e+01, -9.25663337e-02],\n",
              "         [-4.62438507e+01, -5.40768738e+01, -2.11543083e+00,\n",
              "           1.47283773e+01, -2.60020029e-02],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        [[ 2.69571514e+01,  2.28771248e+01,  1.78382568e+02,\n",
              "           1.15163584e+01, -1.59008694e+00],\n",
              "         [-5.08928490e+01, -5.93408737e+01, -2.11543083e+00,\n",
              "           1.40342073e+01, -1.38716936e+00],\n",
              "         [-5.73238487e+01, -8.08608780e+01,  1.76794403e+02,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 3.86751518e+01,  3.59271240e+01,  1.78382568e+02,\n",
              "           1.18397865e+01, -3.30178370e-03],\n",
              "         [-6.52718506e+01, -7.56978760e+01, -2.11543083e+00,\n",
              "           1.41538458e+01, -2.54989696e+00],\n",
              "         [-5.78718491e+01, -8.14558716e+01,  1.76794403e+02,\n",
              "           5.39970458e-01, -2.65888608e-04],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        [[ 4.25091515e+01,  4.01951256e+01,  1.78382568e+02,\n",
              "           1.14771385e+01, -7.25471199e-01],\n",
              "         [-6.99698486e+01, -8.09898758e+01, -2.11543083e+00,\n",
              "           1.41563416e+01,  4.99234255e-03],\n",
              "         [-5.80528488e+01, -8.16518784e+01,  1.76794403e+02,\n",
              "           5.33708394e-01, -1.25271920e-02],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        [[ 4.63441505e+01,  4.44631233e+01,  1.78382568e+02,\n",
              "           1.14784584e+01,  2.64170044e-03],\n",
              "         [-7.49318466e+01, -8.67908783e+01, -2.11543083e+00,\n",
              "           1.52709980e+01,  2.22984457e+00],\n",
              "         [-5.82318497e+01, -8.18458786e+01,  1.76794403e+02,\n",
              "           5.28053939e-01, -1.13115879e-02],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]]],\n",
              "\n",
              "\n",
              "       [[[ 5.16973076e+01, -3.98571801e+00,  2.21932077e+00,\n",
              "           1.22968125e+00, -2.51289129e-01],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        [[ 5.23853073e+01, -3.94271803e+00,  3.21932077e+00,\n",
              "           1.37908208e+00,  2.98887730e-01],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        [[ 5.29933090e+01, -4.01571798e+00,  4.21932077e+00,\n",
              "           1.22366154e+00, -3.10568959e-01],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 5.45023079e+01, -4.09771824e+00,  5.21932077e+00,\n",
              "           7.88318336e-01, -9.41603243e-01],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        [[ 5.48003082e+01, -4.02371788e+00,  4.21932077e+00,\n",
              "           6.14227474e-01, -3.48253399e-01],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        [[ 5.50473061e+01, -4.15671825e+00,  4.21932077e+00,\n",
              "           5.61228156e-01, -1.06029883e-01],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]]],\n",
              "\n",
              "\n",
              "       [[[ 8.91933441e+00, -1.29843588e+01,  5.97617569e+01,\n",
              "           2.12902856e+00,  3.44950676e-01],\n",
              "         [-6.72466612e+00, -1.39013596e+01,  6.47317581e+01,\n",
              "           1.03007412e+01, -3.82869512e-01],\n",
              "         [ 3.42183342e+01, -1.57953587e+01, -1.15568245e+02,\n",
              "           1.00440941e+01, -4.90018040e-01],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        [[ 8.01433372e+00, -1.25183592e+01,  5.83617592e+01,\n",
              "           2.03623819e+00, -1.85615018e-01],\n",
              "         [-1.16046658e+01, -1.17723589e+01,  6.47317581e+01,\n",
              "           1.06503687e+01,  6.99385524e-01],\n",
              "         [ 3.88763351e+01, -1.78083591e+01, -1.15568245e+02,\n",
              "           1.01506081e+01,  2.13067308e-01],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        [[ 6.98733377e+00, -1.16803589e+01,  5.49617577e+01,\n",
              "           2.20734906e+00,  2.84948200e-01],\n",
              "         [-1.64846668e+01, -9.64435959e+00,  6.47317581e+01,\n",
              "           8.86563206e+00, -2.97209358e+00],\n",
              "         [ 4.42533340e+01, -2.01363583e+01, -1.15568245e+02,\n",
              "           9.75744724e+00, -6.54725671e-01],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 3.54833388e+00, -8.49635887e+00,  4.13617592e+01,\n",
              "           4.25577879e+00,  2.49918818e+00],\n",
              "         [-2.91546669e+01, -4.23035908e+00,  6.47317581e+01,\n",
              "           9.64688778e+00, -1.38995326e+00],\n",
              "         [ 5.51543350e+01, -2.48433590e+01, -1.15568245e+02,\n",
              "           8.06057072e+00, -2.22112441e+00],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        [[ 2.27733397e+00, -6.71135902e+00,  3.37617569e+01,\n",
              "           4.38840437e+00,  2.65605479e-01],\n",
              "         [-3.34566650e+01, -2.29335904e+00,  6.47317581e+01,\n",
              "           9.44855022e+00, -3.97207528e-01],\n",
              "         [ 5.96523323e+01, -2.69123592e+01, -1.15568245e+02,\n",
              "           9.91532135e+00,  3.71446347e+00],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]],\n",
              "\n",
              "        [[ 1.00433397e+00, -4.33235931e+00,  2.51617584e+01,\n",
              "           4.90910006e+00,  9.47360814e-01],\n",
              "         [-3.82396660e+01, -1.47359133e-01,  6.47317581e+01,\n",
              "           9.53802586e+00,  1.62794173e-01],\n",
              "         [ 6.41833344e+01, -2.89053593e+01, -1.15568245e+02,\n",
              "           9.00600147e+00, -1.65442860e+00],\n",
              "         ...,\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00],\n",
              "         [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "           0.00000000e+00,  0.00000000e+00]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 345
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTAg0YO_zmOQ",
        "outputId": "8ff9a666-44ec-46d5-83f3-d70e3980b725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(16, 8, 10, 3), dtype=float32, numpy=\n",
              "array([[[[-3.32868665e-01,  1.79106975e+00,  2.74370174e+01],\n",
              "         [-3.32868069e-01,  1.79106975e+00,  2.74370174e+01],\n",
              "         [-3.32868487e-01,  1.79106975e+00,  2.74370193e+01],\n",
              "         ...,\n",
              "         [-3.32868785e-01,  1.79106891e+00,  2.74370174e+01],\n",
              "         [-3.32868785e-01,  1.79106891e+00,  2.74370174e+01],\n",
              "         [-3.32868785e-01,  1.79106891e+00,  2.74370174e+01]],\n",
              "\n",
              "        [[-2.80308574e-01,  1.56844592e+00,  2.74878788e+01],\n",
              "         [-2.80308098e-01,  1.56844592e+00,  2.74878807e+01],\n",
              "         [-2.80307978e-01,  1.56844544e+00,  2.74878807e+01],\n",
              "         ...,\n",
              "         [-2.80308634e-01,  1.56844592e+00,  2.74878769e+01],\n",
              "         [-2.80308634e-01,  1.56844592e+00,  2.74878769e+01],\n",
              "         [-2.80308634e-01,  1.56844592e+00,  2.74878769e+01]],\n",
              "\n",
              "        [[-3.15515734e-02,  1.34530592e+00,  2.75404224e+01],\n",
              "         [-3.15514542e-02,  1.34530556e+00,  2.75404205e+01],\n",
              "         [-3.15516330e-02,  1.34530628e+00,  2.75404205e+01],\n",
              "         ...,\n",
              "         [-3.15515138e-02,  1.34530580e+00,  2.75404205e+01],\n",
              "         [-3.15515138e-02,  1.34530580e+00,  2.75404205e+01],\n",
              "         [-3.15515138e-02,  1.34530580e+00,  2.75404205e+01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 1.30595118e-01,  1.56538284e+00,  2.74404144e+01],\n",
              "         [ 1.30595654e-01,  1.56538188e+00,  2.74404106e+01],\n",
              "         [ 1.30594999e-01,  1.56538308e+00,  2.74404125e+01],\n",
              "         ...,\n",
              "         [ 1.30594999e-01,  1.56538212e+00,  2.74404144e+01],\n",
              "         [ 1.30594999e-01,  1.56538212e+00,  2.74404144e+01],\n",
              "         [ 1.30594999e-01,  1.56538212e+00,  2.74404144e+01]],\n",
              "\n",
              "        [[ 7.17079267e-02,  1.60480499e+00,  2.74141865e+01],\n",
              "         [ 7.17082247e-02,  1.60480523e+00,  2.74141865e+01],\n",
              "         [ 7.17079863e-02,  1.60480618e+00,  2.74141865e+01],\n",
              "         ...,\n",
              "         [ 7.17083439e-02,  1.60480511e+00,  2.74141865e+01],\n",
              "         [ 7.17083439e-02,  1.60480511e+00,  2.74141865e+01],\n",
              "         [ 7.17083439e-02,  1.60480511e+00,  2.74141865e+01]],\n",
              "\n",
              "        [[ 7.29488954e-02,  1.59156334e+00,  2.74071770e+01],\n",
              "         [ 7.29496107e-02,  1.59156263e+00,  2.74071751e+01],\n",
              "         [ 7.29493722e-02,  1.59156299e+00,  2.74071751e+01],\n",
              "         ...,\n",
              "         [ 7.29487762e-02,  1.59156227e+00,  2.74071770e+01],\n",
              "         [ 7.29487762e-02,  1.59156227e+00,  2.74071770e+01],\n",
              "         [ 7.29487762e-02,  1.59156227e+00,  2.74071770e+01]]],\n",
              "\n",
              "\n",
              "       [[[-6.16016722e+00,  7.69875050e+00,  2.30221844e+01],\n",
              "         [-6.16016722e+00,  7.69875050e+00,  2.30221844e+01],\n",
              "         [-6.16016817e+00,  7.69875050e+00,  2.30221844e+01],\n",
              "         ...,\n",
              "         [-6.16016722e+00,  7.69875050e+00,  2.30221825e+01],\n",
              "         [-6.16016722e+00,  7.69875050e+00,  2.30221825e+01],\n",
              "         [-6.16016722e+00,  7.69875050e+00,  2.30221825e+01]],\n",
              "\n",
              "        [[-4.52148247e+00,  6.19667053e+00,  2.48629684e+01],\n",
              "         [-4.52148199e+00,  6.19667006e+00,  2.48629646e+01],\n",
              "         [-4.52148199e+00,  6.19667053e+00,  2.48629646e+01],\n",
              "         ...,\n",
              "         [-4.52148199e+00,  6.19667053e+00,  2.48629684e+01],\n",
              "         [-4.52148199e+00,  6.19667053e+00,  2.48629684e+01],\n",
              "         [-4.52148199e+00,  6.19667053e+00,  2.48629684e+01]],\n",
              "\n",
              "        [[-4.27607441e+00,  5.46953583e+00,  2.54037132e+01],\n",
              "         [-4.27607441e+00,  5.46953678e+00,  2.54037151e+01],\n",
              "         [-4.27607489e+00,  5.46953630e+00,  2.54037151e+01],\n",
              "         ...,\n",
              "         [-4.27607393e+00,  5.46953583e+00,  2.54037170e+01],\n",
              "         [-4.27607393e+00,  5.46953583e+00,  2.54037170e+01],\n",
              "         [-4.27607393e+00,  5.46953583e+00,  2.54037170e+01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-3.73102379e+00,  3.56285310e+00,  2.64568958e+01],\n",
              "         [-3.73102355e+00,  3.56285286e+00,  2.64568958e+01],\n",
              "         [-3.73102355e+00,  3.56285357e+00,  2.64568958e+01],\n",
              "         ...,\n",
              "         [-3.73102379e+00,  3.56285286e+00,  2.64568939e+01],\n",
              "         [-3.73102379e+00,  3.56285286e+00,  2.64568939e+01],\n",
              "         [-3.73102379e+00,  3.56285286e+00,  2.64568939e+01]],\n",
              "\n",
              "        [[-3.03023291e+00,  2.65434098e+00,  2.69355545e+01],\n",
              "         [-3.03023219e+00,  2.65434074e+00,  2.69355545e+01],\n",
              "         [-3.03023195e+00,  2.65434122e+00,  2.69355545e+01],\n",
              "         ...,\n",
              "         [-3.03023195e+00,  2.65434074e+00,  2.69355564e+01],\n",
              "         [-3.03023195e+00,  2.65434074e+00,  2.69355564e+01],\n",
              "         [-3.03023195e+00,  2.65434074e+00,  2.69355564e+01]],\n",
              "\n",
              "        [[-3.34064794e+00,  2.99625778e+00,  2.67532711e+01],\n",
              "         [-3.34064841e+00,  2.99625659e+00,  2.67532711e+01],\n",
              "         [-3.34064841e+00,  2.99625731e+00,  2.67532730e+01],\n",
              "         ...,\n",
              "         [-3.34064841e+00,  2.99625707e+00,  2.67532730e+01],\n",
              "         [-3.34064841e+00,  2.99625707e+00,  2.67532730e+01],\n",
              "         [-3.34064841e+00,  2.99625707e+00,  2.67532730e+01]]],\n",
              "\n",
              "\n",
              "       [[[-5.07405233e+00, -1.50527887e+01,  2.86984468e+00],\n",
              "         [-5.07405233e+00, -1.50527897e+01,  2.86984515e+00],\n",
              "         [-5.07405329e+00, -1.50527887e+01,  2.86984563e+00],\n",
              "         ...,\n",
              "         [-5.07405233e+00, -1.50527897e+01,  2.86984468e+00],\n",
              "         [-5.07405233e+00, -1.50527897e+01,  2.86984468e+00],\n",
              "         [-5.07405233e+00, -1.50527897e+01,  2.86984468e+00]],\n",
              "\n",
              "        [[-4.95994616e+00, -1.49884672e+01,  2.93451142e+00],\n",
              "         [-4.95994616e+00, -1.49884672e+01,  2.93451190e+00],\n",
              "         [-4.95994711e+00, -1.49884682e+01,  2.93451214e+00],\n",
              "         ...,\n",
              "         [-4.95994711e+00, -1.49884682e+01,  2.93451190e+00],\n",
              "         [-4.95994711e+00, -1.49884682e+01,  2.93451190e+00],\n",
              "         [-4.95994711e+00, -1.49884682e+01,  2.93451190e+00]],\n",
              "\n",
              "        [[-4.87652349e+00, -1.49238157e+01,  2.93315291e+00],\n",
              "         [-4.87652445e+00, -1.49238157e+01,  2.93315601e+00],\n",
              "         [-4.87652445e+00, -1.49238138e+01,  2.93315482e+00],\n",
              "         ...,\n",
              "         [-4.87652445e+00, -1.49238148e+01,  2.93315387e+00],\n",
              "         [-4.87652445e+00, -1.49238148e+01,  2.93315387e+00],\n",
              "         [-4.87652445e+00, -1.49238148e+01,  2.93315387e+00]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-2.25739908e+00, -9.19835949e+00, -1.82573719e+01],\n",
              "         [-2.25739884e+00, -9.19835949e+00, -1.82573719e+01],\n",
              "         [-2.25739884e+00, -9.19835949e+00, -1.82573719e+01],\n",
              "         ...,\n",
              "         [-2.25739789e+00, -9.19835758e+00, -1.82573719e+01],\n",
              "         [-2.25739789e+00, -9.19835758e+00, -1.82573719e+01],\n",
              "         [-2.25739789e+00, -9.19835758e+00, -1.82573719e+01]],\n",
              "\n",
              "        [[-1.99500799e+00, -8.76002502e+00, -1.87562065e+01],\n",
              "         [-1.99500751e+00, -8.76002407e+00, -1.87562065e+01],\n",
              "         [-1.99500811e+00, -8.76002598e+00, -1.87562065e+01],\n",
              "         ...,\n",
              "         [-1.99500775e+00, -8.76002312e+00, -1.87562046e+01],\n",
              "         [-1.99500775e+00, -8.76002312e+00, -1.87562046e+01],\n",
              "         [-1.99500775e+00, -8.76002312e+00, -1.87562046e+01]],\n",
              "\n",
              "        [[-1.89080095e+00, -8.67802048e+00, -1.86603241e+01],\n",
              "         [-1.89080060e+00, -8.67801952e+00, -1.86603203e+01],\n",
              "         [-1.89080048e+00, -8.67802143e+00, -1.86603241e+01],\n",
              "         ...,\n",
              "         [-1.89080071e+00, -8.67801952e+00, -1.86603241e+01],\n",
              "         [-1.89080071e+00, -8.67801952e+00, -1.86603241e+01],\n",
              "         [-1.89080071e+00, -8.67801952e+00, -1.86603241e+01]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[ 1.03315674e-01, -3.21125269e+00,  2.76980839e+01],\n",
              "         [ 1.03315555e-01, -3.21125269e+00,  2.76980839e+01],\n",
              "         [ 1.03315912e-01, -3.21125317e+00,  2.76980839e+01],\n",
              "         ...,\n",
              "         [ 1.03315912e-01, -3.21125317e+00,  2.76980839e+01],\n",
              "         [ 1.03315912e-01, -3.21125317e+00,  2.76980839e+01],\n",
              "         [ 1.03315912e-01, -3.21125317e+00,  2.76980839e+01]],\n",
              "\n",
              "        [[-2.48704404e-01, -2.85663843e+00,  2.77458897e+01],\n",
              "         [-2.48705238e-01, -2.85663795e+00,  2.77458878e+01],\n",
              "         [-2.48704702e-01, -2.85663891e+00,  2.77458897e+01],\n",
              "         ...,\n",
              "         [-2.48704702e-01, -2.85663891e+00,  2.77458897e+01],\n",
              "         [-2.48704702e-01, -2.85663891e+00,  2.77458897e+01],\n",
              "         [-2.48704702e-01, -2.85663891e+00,  2.77458897e+01]],\n",
              "\n",
              "        [[-2.18709201e-01, -2.62307477e+00,  2.77440510e+01],\n",
              "         [-2.18708783e-01, -2.62307525e+00,  2.77440472e+01],\n",
              "         [-2.18709618e-01, -2.62307477e+00,  2.77440510e+01],\n",
              "         ...,\n",
              "         [-2.18709916e-01, -2.62307549e+00,  2.77440510e+01],\n",
              "         [-2.18709916e-01, -2.62307549e+00,  2.77440510e+01],\n",
              "         [-2.18709916e-01, -2.62307549e+00,  2.77440510e+01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 2.03349024e-01, -1.82686222e+00,  2.78411121e+01],\n",
              "         [ 2.03349084e-01, -1.82686257e+00,  2.78411102e+01],\n",
              "         [ 2.03349382e-01, -1.82686257e+00,  2.78411140e+01],\n",
              "         ...,\n",
              "         [ 2.03349143e-01, -1.82686329e+00,  2.78411140e+01],\n",
              "         [ 2.03349143e-01, -1.82686329e+00,  2.78411140e+01],\n",
              "         [ 2.03349143e-01, -1.82686329e+00,  2.78411140e+01]],\n",
              "\n",
              "        [[ 1.48956567e-01, -1.61816621e+00,  2.78425198e+01],\n",
              "         [ 1.48957044e-01, -1.61816609e+00,  2.78425179e+01],\n",
              "         [ 1.48956805e-01, -1.61816621e+00,  2.78425179e+01],\n",
              "         ...,\n",
              "         [ 1.48956627e-01, -1.61816645e+00,  2.78425179e+01],\n",
              "         [ 1.48956627e-01, -1.61816645e+00,  2.78425179e+01],\n",
              "         [ 1.48956627e-01, -1.61816645e+00,  2.78425179e+01]],\n",
              "\n",
              "        [[ 2.45813221e-01, -1.37226081e+00,  2.78518867e+01],\n",
              "         [ 2.45813698e-01, -1.37226140e+00,  2.78518867e+01],\n",
              "         [ 2.45813519e-01, -1.37226033e+00,  2.78518887e+01],\n",
              "         ...,\n",
              "         [ 2.45813698e-01, -1.37226093e+00,  2.78518867e+01],\n",
              "         [ 2.45813698e-01, -1.37226093e+00,  2.78518867e+01],\n",
              "         [ 2.45813698e-01, -1.37226093e+00,  2.78518867e+01]]],\n",
              "\n",
              "\n",
              "       [[[ 3.57145619e+00,  7.13069215e-02, -8.95213306e-01],\n",
              "         [ 3.57145572e+00,  7.13064447e-02, -8.95213187e-01],\n",
              "         [ 3.57145572e+00,  7.13064447e-02, -8.95213187e-01],\n",
              "         ...,\n",
              "         [ 3.57145572e+00,  7.13064447e-02, -8.95213187e-01],\n",
              "         [ 3.57145572e+00,  7.13064447e-02, -8.95213187e-01],\n",
              "         [ 3.57145572e+00,  7.13064447e-02, -8.95213187e-01]],\n",
              "\n",
              "        [[ 3.48301291e+00,  6.29523173e-02, -9.33596671e-01],\n",
              "         [ 3.48301291e+00,  6.29521981e-02, -9.33596611e-01],\n",
              "         [ 3.48301291e+00,  6.29521981e-02, -9.33596611e-01],\n",
              "         ...,\n",
              "         [ 3.48301291e+00,  6.29521981e-02, -9.33596611e-01],\n",
              "         [ 3.48301291e+00,  6.29521981e-02, -9.33596611e-01],\n",
              "         [ 3.48301291e+00,  6.29521981e-02, -9.33596611e-01]],\n",
              "\n",
              "        [[ 3.48302317e+00,  6.53705373e-02, -9.32995558e-01],\n",
              "         [ 3.48302388e+00,  6.53704777e-02, -9.32995319e-01],\n",
              "         [ 3.48302388e+00,  6.53704777e-02, -9.32995319e-01],\n",
              "         ...,\n",
              "         [ 3.48302388e+00,  6.53704777e-02, -9.32995319e-01],\n",
              "         [ 3.48302388e+00,  6.53704777e-02, -9.32995319e-01],\n",
              "         [ 3.48302388e+00,  6.53704777e-02, -9.32995319e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 3.43872237e+00,  1.73990522e-02, -1.01449990e+00],\n",
              "         [ 3.43872261e+00,  1.73994694e-02, -1.01449990e+00],\n",
              "         [ 3.43872261e+00,  1.73994694e-02, -1.01449990e+00],\n",
              "         ...,\n",
              "         [ 3.43872261e+00,  1.73994694e-02, -1.01449990e+00],\n",
              "         [ 3.43872261e+00,  1.73994694e-02, -1.01449990e+00],\n",
              "         [ 3.43872261e+00,  1.73994694e-02, -1.01449990e+00]],\n",
              "\n",
              "        [[ 3.39203238e+00,  9.71833803e-03, -1.11317265e+00],\n",
              "         [ 3.39203262e+00,  9.71815921e-03, -1.11317348e+00],\n",
              "         [ 3.39203262e+00,  9.71815921e-03, -1.11317348e+00],\n",
              "         ...,\n",
              "         [ 3.39203262e+00,  9.71815921e-03, -1.11317348e+00],\n",
              "         [ 3.39203262e+00,  9.71815921e-03, -1.11317348e+00],\n",
              "         [ 3.39203262e+00,  9.71815921e-03, -1.11317348e+00]],\n",
              "\n",
              "        [[ 3.44114590e+00,  1.98855195e-02, -1.01785779e+00],\n",
              "         [ 3.44114590e+00,  1.98855791e-02, -1.01785755e+00],\n",
              "         [ 3.44114590e+00,  1.98855791e-02, -1.01785755e+00],\n",
              "         ...,\n",
              "         [ 3.44114590e+00,  1.98855791e-02, -1.01785755e+00],\n",
              "         [ 3.44114590e+00,  1.98855791e-02, -1.01785755e+00],\n",
              "         [ 3.44114590e+00,  1.98855791e-02, -1.01785755e+00]]],\n",
              "\n",
              "\n",
              "       [[[ 4.95344591e+00, -5.48188543e+00, -5.87674379e+00],\n",
              "         [ 4.95344687e+00, -5.48188591e+00, -5.87674379e+00],\n",
              "         [ 4.95344687e+00, -5.48188543e+00, -5.87674284e+00],\n",
              "         ...,\n",
              "         [ 4.95344543e+00, -5.48188543e+00, -5.87674379e+00],\n",
              "         [ 4.95344543e+00, -5.48188543e+00, -5.87674379e+00],\n",
              "         [ 4.95344543e+00, -5.48188543e+00, -5.87674379e+00]],\n",
              "\n",
              "        [[ 6.89139700e+00, -4.98512745e+00, -3.87535453e+00],\n",
              "         [ 6.89139605e+00, -4.98512793e+00, -3.87535501e+00],\n",
              "         [ 6.89139700e+00, -4.98512745e+00, -3.87535357e+00],\n",
              "         ...,\n",
              "         [ 6.89139700e+00, -4.98512840e+00, -3.87535453e+00],\n",
              "         [ 6.89139700e+00, -4.98512840e+00, -3.87535453e+00],\n",
              "         [ 6.89139700e+00, -4.98512840e+00, -3.87535453e+00]],\n",
              "\n",
              "        [[ 6.92346668e+00, -5.21535301e+00, -3.62757373e+00],\n",
              "         [ 6.92346668e+00, -5.21535254e+00, -3.62757373e+00],\n",
              "         [ 6.92346716e+00, -5.21535349e+00, -3.62757277e+00],\n",
              "         ...,\n",
              "         [ 6.92346716e+00, -5.21535397e+00, -3.62757277e+00],\n",
              "         [ 6.92346716e+00, -5.21535397e+00, -3.62757277e+00],\n",
              "         [ 6.92346716e+00, -5.21535397e+00, -3.62757277e+00]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 8.98968220e+00, -5.15354347e+00, -4.65594053e+00],\n",
              "         [ 8.98968220e+00, -5.15354443e+00, -4.65594244e+00],\n",
              "         [ 8.98968315e+00, -5.15354443e+00, -4.65594101e+00],\n",
              "         ...,\n",
              "         [ 8.98968220e+00, -5.15354443e+00, -4.65594244e+00],\n",
              "         [ 8.98968220e+00, -5.15354443e+00, -4.65594244e+00],\n",
              "         [ 8.98968220e+00, -5.15354443e+00, -4.65594244e+00]],\n",
              "\n",
              "        [[ 8.79938126e+00, -5.01559067e+00, -4.81528807e+00],\n",
              "         [ 8.79938030e+00, -5.01559067e+00, -4.81528711e+00],\n",
              "         [ 8.79938030e+00, -5.01559114e+00, -4.81528807e+00],\n",
              "         ...,\n",
              "         [ 8.79938126e+00, -5.01559067e+00, -4.81528711e+00],\n",
              "         [ 8.79938126e+00, -5.01559067e+00, -4.81528711e+00],\n",
              "         [ 8.79938126e+00, -5.01559067e+00, -4.81528711e+00]],\n",
              "\n",
              "        [[ 8.14000511e+00, -5.32606697e+00, -3.99272799e+00],\n",
              "         [ 8.14000416e+00, -5.32606697e+00, -3.99272799e+00],\n",
              "         [ 8.14000511e+00, -5.32606792e+00, -3.99272799e+00],\n",
              "         ...,\n",
              "         [ 8.14000511e+00, -5.32606792e+00, -3.99272728e+00],\n",
              "         [ 8.14000511e+00, -5.32606792e+00, -3.99272728e+00],\n",
              "         [ 8.14000511e+00, -5.32606792e+00, -3.99272728e+00]]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 344
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing functions"
      ],
      "metadata": {
        "id": "7fnl4A2rpBQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(cubes)):\n",
        "  for j in range(len(cubes[i][0])):\n",
        "    for k in range(len(cubes[i][0][j])):\n",
        "      for l in range(len(cubes[i][0][j][k])):\n",
        "        if np.isnan(cubes[i][0][j][k][l]):\n",
        "          cubes[i][0][j][k][l] = 0.0      \n"
      ],
      "metadata": {
        "id": "0kov85YG8tVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_inps = [x[0] for x in cubes]\n",
        "for inp in all_inps:\n",
        "  for face in inp:\n",
        "    for row in face:\n",
        "      for el in row:\n",
        "        if np.isnan(el):\n",
        "          print('WHAAAAT')"
      ],
      "metadata": {
        "id": "i2yjv0GHqo0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.arange(10)[:, np.newaxis]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NS-_o2cMlZJ3",
        "outputId": "df15b9a2-cac7-4ccc-85db-efd08aa41b10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [2],\n",
              "       [3],\n",
              "       [4],\n",
              "       [5],\n",
              "       [6],\n",
              "       [7],\n",
              "       [8],\n",
              "       [9]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = tf.constant(np.arange(3 * 4 * 3 * 5 * 5)) + 1    \n",
        "t = tf.reshape(t, (3, 4, 3, 5, 5))             #(batch, head, seq, N, N)\n",
        "t = tf.cast(t, tf.float32)\n",
        "t2 = np.random.choice([0, 1], (3, 3, 5)) * 0.5"
      ],
      "metadata": {
        "id": "v0gPWcILo_po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t2 = tf.reshape(t2, (3, 1, 3, 1, 5))          # (batch, 1, seq, 1, N)\n",
        "t2 = tf.cast(t2, tf.float32)"
      ],
      "metadata": {
        "id": "6IIzQ0yfpn7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nP96rZJ2qmSG",
        "outputId": "db500925-f633-4f9b-8cb5-32822eda9bf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 1, 3, 1, 5), dtype=float32, numpy=\n",
              "array([[[[[0. , 0. , 0. , 0.5, 0. ]],\n",
              "\n",
              "         [[0. , 0.5, 0.5, 0.5, 0.5]],\n",
              "\n",
              "         [[0. , 0.5, 0. , 0.5, 0. ]]]],\n",
              "\n",
              "\n",
              "\n",
              "       [[[[0.5, 0. , 0.5, 0. , 0. ]],\n",
              "\n",
              "         [[0.5, 0. , 0. , 0. , 0.5]],\n",
              "\n",
              "         [[0. , 0. , 0.5, 0.5, 0.5]]]],\n",
              "\n",
              "\n",
              "\n",
              "       [[[[0. , 0. , 0.5, 0. , 0. ]],\n",
              "\n",
              "         [[0. , 0. , 0. , 0.5, 0. ]],\n",
              "\n",
              "         [[0.5, 0.5, 0.5, 0. , 0. ]]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t + t2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "il7hgzCmqokY",
        "outputId": "ad8395a6-b210-4e3b-976a-e5693dcdad32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 4, 3, 5, 5), dtype=float32, numpy=\n",
              "array([[[[[  1. ,   2. ,   3. ,   4.5,   5. ],\n",
              "          [  6. ,   7. ,   8. ,   9.5,  10. ],\n",
              "          [ 11. ,  12. ,  13. ,  14.5,  15. ],\n",
              "          [ 16. ,  17. ,  18. ,  19.5,  20. ],\n",
              "          [ 21. ,  22. ,  23. ,  24.5,  25. ]],\n",
              "\n",
              "         [[ 26. ,  27.5,  28.5,  29.5,  30.5],\n",
              "          [ 31. ,  32.5,  33.5,  34.5,  35.5],\n",
              "          [ 36. ,  37.5,  38.5,  39.5,  40.5],\n",
              "          [ 41. ,  42.5,  43.5,  44.5,  45.5],\n",
              "          [ 46. ,  47.5,  48.5,  49.5,  50.5]],\n",
              "\n",
              "         [[ 51. ,  52.5,  53. ,  54.5,  55. ],\n",
              "          [ 56. ,  57.5,  58. ,  59.5,  60. ],\n",
              "          [ 61. ,  62.5,  63. ,  64.5,  65. ],\n",
              "          [ 66. ,  67.5,  68. ,  69.5,  70. ],\n",
              "          [ 71. ,  72.5,  73. ,  74.5,  75. ]]],\n",
              "\n",
              "\n",
              "        [[[ 76. ,  77. ,  78. ,  79.5,  80. ],\n",
              "          [ 81. ,  82. ,  83. ,  84.5,  85. ],\n",
              "          [ 86. ,  87. ,  88. ,  89.5,  90. ],\n",
              "          [ 91. ,  92. ,  93. ,  94.5,  95. ],\n",
              "          [ 96. ,  97. ,  98. ,  99.5, 100. ]],\n",
              "\n",
              "         [[101. , 102.5, 103.5, 104.5, 105.5],\n",
              "          [106. , 107.5, 108.5, 109.5, 110.5],\n",
              "          [111. , 112.5, 113.5, 114.5, 115.5],\n",
              "          [116. , 117.5, 118.5, 119.5, 120.5],\n",
              "          [121. , 122.5, 123.5, 124.5, 125.5]],\n",
              "\n",
              "         [[126. , 127.5, 128. , 129.5, 130. ],\n",
              "          [131. , 132.5, 133. , 134.5, 135. ],\n",
              "          [136. , 137.5, 138. , 139.5, 140. ],\n",
              "          [141. , 142.5, 143. , 144.5, 145. ],\n",
              "          [146. , 147.5, 148. , 149.5, 150. ]]],\n",
              "\n",
              "\n",
              "        [[[151. , 152. , 153. , 154.5, 155. ],\n",
              "          [156. , 157. , 158. , 159.5, 160. ],\n",
              "          [161. , 162. , 163. , 164.5, 165. ],\n",
              "          [166. , 167. , 168. , 169.5, 170. ],\n",
              "          [171. , 172. , 173. , 174.5, 175. ]],\n",
              "\n",
              "         [[176. , 177.5, 178.5, 179.5, 180.5],\n",
              "          [181. , 182.5, 183.5, 184.5, 185.5],\n",
              "          [186. , 187.5, 188.5, 189.5, 190.5],\n",
              "          [191. , 192.5, 193.5, 194.5, 195.5],\n",
              "          [196. , 197.5, 198.5, 199.5, 200.5]],\n",
              "\n",
              "         [[201. , 202.5, 203. , 204.5, 205. ],\n",
              "          [206. , 207.5, 208. , 209.5, 210. ],\n",
              "          [211. , 212.5, 213. , 214.5, 215. ],\n",
              "          [216. , 217.5, 218. , 219.5, 220. ],\n",
              "          [221. , 222.5, 223. , 224.5, 225. ]]],\n",
              "\n",
              "\n",
              "        [[[226. , 227. , 228. , 229.5, 230. ],\n",
              "          [231. , 232. , 233. , 234.5, 235. ],\n",
              "          [236. , 237. , 238. , 239.5, 240. ],\n",
              "          [241. , 242. , 243. , 244.5, 245. ],\n",
              "          [246. , 247. , 248. , 249.5, 250. ]],\n",
              "\n",
              "         [[251. , 252.5, 253.5, 254.5, 255.5],\n",
              "          [256. , 257.5, 258.5, 259.5, 260.5],\n",
              "          [261. , 262.5, 263.5, 264.5, 265.5],\n",
              "          [266. , 267.5, 268.5, 269.5, 270.5],\n",
              "          [271. , 272.5, 273.5, 274.5, 275.5]],\n",
              "\n",
              "         [[276. , 277.5, 278. , 279.5, 280. ],\n",
              "          [281. , 282.5, 283. , 284.5, 285. ],\n",
              "          [286. , 287.5, 288. , 289.5, 290. ],\n",
              "          [291. , 292.5, 293. , 294.5, 295. ],\n",
              "          [296. , 297.5, 298. , 299.5, 300. ]]]],\n",
              "\n",
              "\n",
              "\n",
              "       [[[[301.5, 302. , 303.5, 304. , 305. ],\n",
              "          [306.5, 307. , 308.5, 309. , 310. ],\n",
              "          [311.5, 312. , 313.5, 314. , 315. ],\n",
              "          [316.5, 317. , 318.5, 319. , 320. ],\n",
              "          [321.5, 322. , 323.5, 324. , 325. ]],\n",
              "\n",
              "         [[326.5, 327. , 328. , 329. , 330.5],\n",
              "          [331.5, 332. , 333. , 334. , 335.5],\n",
              "          [336.5, 337. , 338. , 339. , 340.5],\n",
              "          [341.5, 342. , 343. , 344. , 345.5],\n",
              "          [346.5, 347. , 348. , 349. , 350.5]],\n",
              "\n",
              "         [[351. , 352. , 353.5, 354.5, 355.5],\n",
              "          [356. , 357. , 358.5, 359.5, 360.5],\n",
              "          [361. , 362. , 363.5, 364.5, 365.5],\n",
              "          [366. , 367. , 368.5, 369.5, 370.5],\n",
              "          [371. , 372. , 373.5, 374.5, 375.5]]],\n",
              "\n",
              "\n",
              "        [[[376.5, 377. , 378.5, 379. , 380. ],\n",
              "          [381.5, 382. , 383.5, 384. , 385. ],\n",
              "          [386.5, 387. , 388.5, 389. , 390. ],\n",
              "          [391.5, 392. , 393.5, 394. , 395. ],\n",
              "          [396.5, 397. , 398.5, 399. , 400. ]],\n",
              "\n",
              "         [[401.5, 402. , 403. , 404. , 405.5],\n",
              "          [406.5, 407. , 408. , 409. , 410.5],\n",
              "          [411.5, 412. , 413. , 414. , 415.5],\n",
              "          [416.5, 417. , 418. , 419. , 420.5],\n",
              "          [421.5, 422. , 423. , 424. , 425.5]],\n",
              "\n",
              "         [[426. , 427. , 428.5, 429.5, 430.5],\n",
              "          [431. , 432. , 433.5, 434.5, 435.5],\n",
              "          [436. , 437. , 438.5, 439.5, 440.5],\n",
              "          [441. , 442. , 443.5, 444.5, 445.5],\n",
              "          [446. , 447. , 448.5, 449.5, 450.5]]],\n",
              "\n",
              "\n",
              "        [[[451.5, 452. , 453.5, 454. , 455. ],\n",
              "          [456.5, 457. , 458.5, 459. , 460. ],\n",
              "          [461.5, 462. , 463.5, 464. , 465. ],\n",
              "          [466.5, 467. , 468.5, 469. , 470. ],\n",
              "          [471.5, 472. , 473.5, 474. , 475. ]],\n",
              "\n",
              "         [[476.5, 477. , 478. , 479. , 480.5],\n",
              "          [481.5, 482. , 483. , 484. , 485.5],\n",
              "          [486.5, 487. , 488. , 489. , 490.5],\n",
              "          [491.5, 492. , 493. , 494. , 495.5],\n",
              "          [496.5, 497. , 498. , 499. , 500.5]],\n",
              "\n",
              "         [[501. , 502. , 503.5, 504.5, 505.5],\n",
              "          [506. , 507. , 508.5, 509.5, 510.5],\n",
              "          [511. , 512. , 513.5, 514.5, 515.5],\n",
              "          [516. , 517. , 518.5, 519.5, 520.5],\n",
              "          [521. , 522. , 523.5, 524.5, 525.5]]],\n",
              "\n",
              "\n",
              "        [[[526.5, 527. , 528.5, 529. , 530. ],\n",
              "          [531.5, 532. , 533.5, 534. , 535. ],\n",
              "          [536.5, 537. , 538.5, 539. , 540. ],\n",
              "          [541.5, 542. , 543.5, 544. , 545. ],\n",
              "          [546.5, 547. , 548.5, 549. , 550. ]],\n",
              "\n",
              "         [[551.5, 552. , 553. , 554. , 555.5],\n",
              "          [556.5, 557. , 558. , 559. , 560.5],\n",
              "          [561.5, 562. , 563. , 564. , 565.5],\n",
              "          [566.5, 567. , 568. , 569. , 570.5],\n",
              "          [571.5, 572. , 573. , 574. , 575.5]],\n",
              "\n",
              "         [[576. , 577. , 578.5, 579.5, 580.5],\n",
              "          [581. , 582. , 583.5, 584.5, 585.5],\n",
              "          [586. , 587. , 588.5, 589.5, 590.5],\n",
              "          [591. , 592. , 593.5, 594.5, 595.5],\n",
              "          [596. , 597. , 598.5, 599.5, 600.5]]]],\n",
              "\n",
              "\n",
              "\n",
              "       [[[[601. , 602. , 603.5, 604. , 605. ],\n",
              "          [606. , 607. , 608.5, 609. , 610. ],\n",
              "          [611. , 612. , 613.5, 614. , 615. ],\n",
              "          [616. , 617. , 618.5, 619. , 620. ],\n",
              "          [621. , 622. , 623.5, 624. , 625. ]],\n",
              "\n",
              "         [[626. , 627. , 628. , 629.5, 630. ],\n",
              "          [631. , 632. , 633. , 634.5, 635. ],\n",
              "          [636. , 637. , 638. , 639.5, 640. ],\n",
              "          [641. , 642. , 643. , 644.5, 645. ],\n",
              "          [646. , 647. , 648. , 649.5, 650. ]],\n",
              "\n",
              "         [[651.5, 652.5, 653.5, 654. , 655. ],\n",
              "          [656.5, 657.5, 658.5, 659. , 660. ],\n",
              "          [661.5, 662.5, 663.5, 664. , 665. ],\n",
              "          [666.5, 667.5, 668.5, 669. , 670. ],\n",
              "          [671.5, 672.5, 673.5, 674. , 675. ]]],\n",
              "\n",
              "\n",
              "        [[[676. , 677. , 678.5, 679. , 680. ],\n",
              "          [681. , 682. , 683.5, 684. , 685. ],\n",
              "          [686. , 687. , 688.5, 689. , 690. ],\n",
              "          [691. , 692. , 693.5, 694. , 695. ],\n",
              "          [696. , 697. , 698.5, 699. , 700. ]],\n",
              "\n",
              "         [[701. , 702. , 703. , 704.5, 705. ],\n",
              "          [706. , 707. , 708. , 709.5, 710. ],\n",
              "          [711. , 712. , 713. , 714.5, 715. ],\n",
              "          [716. , 717. , 718. , 719.5, 720. ],\n",
              "          [721. , 722. , 723. , 724.5, 725. ]],\n",
              "\n",
              "         [[726.5, 727.5, 728.5, 729. , 730. ],\n",
              "          [731.5, 732.5, 733.5, 734. , 735. ],\n",
              "          [736.5, 737.5, 738.5, 739. , 740. ],\n",
              "          [741.5, 742.5, 743.5, 744. , 745. ],\n",
              "          [746.5, 747.5, 748.5, 749. , 750. ]]],\n",
              "\n",
              "\n",
              "        [[[751. , 752. , 753.5, 754. , 755. ],\n",
              "          [756. , 757. , 758.5, 759. , 760. ],\n",
              "          [761. , 762. , 763.5, 764. , 765. ],\n",
              "          [766. , 767. , 768.5, 769. , 770. ],\n",
              "          [771. , 772. , 773.5, 774. , 775. ]],\n",
              "\n",
              "         [[776. , 777. , 778. , 779.5, 780. ],\n",
              "          [781. , 782. , 783. , 784.5, 785. ],\n",
              "          [786. , 787. , 788. , 789.5, 790. ],\n",
              "          [791. , 792. , 793. , 794.5, 795. ],\n",
              "          [796. , 797. , 798. , 799.5, 800. ]],\n",
              "\n",
              "         [[801.5, 802.5, 803.5, 804. , 805. ],\n",
              "          [806.5, 807.5, 808.5, 809. , 810. ],\n",
              "          [811.5, 812.5, 813.5, 814. , 815. ],\n",
              "          [816.5, 817.5, 818.5, 819. , 820. ],\n",
              "          [821.5, 822.5, 823.5, 824. , 825. ]]],\n",
              "\n",
              "\n",
              "        [[[826. , 827. , 828.5, 829. , 830. ],\n",
              "          [831. , 832. , 833.5, 834. , 835. ],\n",
              "          [836. , 837. , 838.5, 839. , 840. ],\n",
              "          [841. , 842. , 843.5, 844. , 845. ],\n",
              "          [846. , 847. , 848.5, 849. , 850. ]],\n",
              "\n",
              "         [[851. , 852. , 853. , 854.5, 855. ],\n",
              "          [856. , 857. , 858. , 859.5, 860. ],\n",
              "          [861. , 862. , 863. , 864.5, 865. ],\n",
              "          [866. , 867. , 868. , 869.5, 870. ],\n",
              "          [871. , 872. , 873. , 874.5, 875. ]],\n",
              "\n",
              "         [[876.5, 877.5, 878.5, 879. , 880. ],\n",
              "          [881.5, 882.5, 883.5, 884. , 885. ],\n",
              "          [886.5, 887.5, 888.5, 889. , 890. ],\n",
              "          [891.5, 892.5, 893.5, 894. , 895. ],\n",
              "          [896.5, 897.5, 898.5, 899. , 900. ]]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = np.random.choice([0, 1], size=(3, 5))"
      ],
      "metadata": {
        "id": "XfRj6BV9U-Ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Gy4I67yVG1X",
        "outputId": "1d9a1849-9433-40a0-be14-a3b6603de2ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0, 1],\n",
              "       [1, 1, 0, 0, 1],\n",
              "       [0, 1, 0, 1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adapt_spatial_mask(mask).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTMo8uEhVJVQ",
        "outputId": "b8d4d91e-d68e-4aff-f708-70e1ba6d4bcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 3, 1, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}